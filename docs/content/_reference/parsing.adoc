== Matching, parsing and validating

.The `Production` concept
[source,cpp]
----
struct Production
{
    static constexpr auto rule = …;
    static constexpr auto whitespace = …; // optional

    static constexpr auto value = …; // optional
};
----

A `Production` is type containing a rule and optional callbacks that produce the value.
A grammar contains an entry production where parsing begins and all productions referenced by it.

TIP: It is recommended to put all productions of a grammar into a separate namespace.

By passing the entry production of the grammar to `lexy::match()`, `lexy::parse()`, or `lexy::validate()`, the production is parsed.

[discrete]
=== Matching

.`lexy/match.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename Production, typename Input>
    constexpr bool match(const Input& input);
}
----

The function `lexy::match()` matches the `Production` on the given `input`.
If the production accepts the input, returns `true`, otherwise, returns `false`.
It will discard any values produced and does not give detailed information about why the production did not accept the input.

NOTE: A production does not necessarily need to consume the entire input for it to match.
Add `lexy::dsl::eof` to the end if the production should consume the entire input.

[discrete]
=== Validating

.`lexy/validate.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename ErrorCallback>
    class validate_result
    {
    public:
        using error_callback = ErrorCallback;
        using error_type     = /* return type of the sink */;

        constexpr explicit operator bool() const noexcept
        {
            return is_success();
        }

        constexpr bool is_success() const noexcept; // <1>
        constexpr bool is_error() const noexcept; // <2>
        constexpr bool is_recovered_error() const noexcept; // <3>
        constexpr bool is_fatal_error() const noexcept; // <4>

        constexpr std::size_t error_count() const noexcept;

        constexpr const error_type& errors() const& noexcept;
        constexpr error_type&& errors() && noexcept;
    };

    template <typename Production, typename Input, typename ErrorCallback>
    constexpr auto validate(const Input& input, ErrorCallback error_callback)
        -> validate_result<ErrorCallback>;
}
----
<1> Returns `true` if no error occurred during validation.
<2> Returns `true` if at least one error occurred during validation.
<3> Returns `true` if at least one error occurred during validation, but parsing could recover after all of them.
<4> Returns `true` if at least one error occurred during validation and parsing had to cancel.

The function `lexy::validate()` validates that the `Production` matches on the given `input`.
If a parse error occurs, it will invoke the error callback (see <<Error handling>>); all errors are then returned.
It will discard any values produced.

NOTE: A production does not necessarily need to consume the entire input for it to match.
Add `lexy::dsl::eof` to the end if the production should consume the entire input.

[discrete]
=== Parsing

.`lexy/parse.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename T, typename ErrorCallback>
    class parse_result
    {
    public:
        using value_type     = T;
        using error_callback = ErrorCallback;
        using error_type     = /* return type of the sink */;

        //=== status ===//
        constexpr explicit operator bool() const noexcept
        {
            return is_success();
        }

        constexpr bool is_success() const noexcept; // <1>
        constexpr bool is_error() const noexcept; // <2>
        constexpr bool is_recovered_error() const noexcept; // <3>
        constexpr bool is_fatal_error() const noexcept; // <4>

        //=== value ===//
        constexpr bool has_value() const noexcept; // <5>

        constexpr const T& value() const& noexcept;
        constexpr T&& value() && noexcept;

        //=== error ===//
        constexpr std::size_t error_count() const noexcept;

        constexpr const error_type& errors() const& noexcept;
        constexpr error_type&& errors() && noexcept;
    };

    template <typename Production, typename Input, typename ErrorCallback>
    constexpr auto parse(const Input& input, ErrorCallback error_callback)
        -> parse_result</* see below */, ErrorCallback>;

    template <typename Production, typename Input, typename State, typename ErrorCallback>
    constexpr auto parse(const Input& input, State&& state, ErrorCallback error_callback)
        -> parse_result</* see below */, ErrorCallback>;
}
----
<1> Returns `true` if no error occurred during parsing.
<2> Returns `true` if at least one error occurred during parsing.
<3> Returns `true` if at least one error occurred during parsing, but parsing could recover after all of them.
<4> Returns `true` if at least one error occurred during parsing and parsing had to cancel.
<5> Returns `true` if parsing could produce a value. This can only happen if there was no fatal error.

The function `lexy::parse()` parses the `Production` on the given `input`.
The return value is a `lexy::parse_result<T, ErrorCallback>`, where `T` is the return type of the `Production::value` or `Production::list` callback.
If the production accepts the input or there are only recoverable errors, invokes `Production::value` (see below) with the produced values and returns their result.
Invokes the error callback for each parse error (see <<Error handling>>) and collects the errors.

The return value on success is determined using `Production::value` depending on three cases:

* `Production::rule` does not contain a list. Then all arguments will be forwarded to `Production::value` as a callback whose result is returned.
  The `Production::value` callback must be present.
* `Production::rule` contains a list and no other rule produces a value. Then `Production::value` will be used as sink for the list values.
  If `Production::value` is also a callback that accepts the result of the sink as argument,
  it will be invoked with the sink result and the processed result returned.
  Otherwise, the result of the sink is the final result.
* `Production::rule` contains a list and other rules produce values as well.
  Then `Production::value` will be used as sink for the list values.
  The sink result will be added to the other values in order and everything forwarded to `Production::value` as a callback.
  The callback result is then returned.

NOTE: The callback `operator>>` is useful for case 3 to create a combined callback and sink with the desired behavior.

The second overload of `lexy::parse()` allows passing an arbitrary state argument.
This will be made available to the `lexy::dsl::parse_state` and `lexy::dsl::parse_state_member` rules which can forward it to the `Production::value` callback.

=== Callbacks

.The `Callback` concept
[source,cpp]
----
struct Callback
{
    using return_type = …;

    return_type operator()(Args&&... args) const;
};

struct Sink
{
    class _sink // exposition only
    {
    public:
        using return_type = …;

        void operator()(Args&&... args);

        return_type&& finish() &&;
    };

    _sink sink() const;
};
----

A `Callback` is a function object whose return type is specified by a member typedef.
A `Sink` is a type with a `sink()` member function that returns a callback.
The callback can be invoked multiple times and the final value is return by calling `.finish()`.

Callbacks are used by `lexy` to compute the parse result and handle error values.
They can either be written manually implementing to the above concepts or composed from the pre-defined concepts.

==== Callback adapters

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename ReturnType = void, typename... Fns>
    constexpr Callback callback(Fns&&... fns);
}
----

Creates a callback with the given `ReturnType` from multiple functions.
When calling the resulting callback, it will use overload resolution to determine the correct function to call.
It supports function pointers, lambdas, and member function or data pointers.

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename T, typename... Fns>
    constexpr Sink sink(Fns&&... fns);
}
----

Creates a sink constructing the given `T` using the given functions.
The sink will value-construct the `T` and then call one of the functions selected by overload resolution, passing it a reference to the resulting object as first argument.
It supports function pointers, lambdas, and member function or data pointers.

.Example
[%collapsible]
====
Creating a sink that will add all values.

[source,cpp]
----
constexpr auto adder = lexy::sink<int>([](int& cur, int arg) { cur += arg; }); // <1>

auto s = adder.sink(); // <2>
s(1);
s(2);
s(3);
auto result = std::move(s).finish();
assert(result == 1 + 2 + 3);
----
<1> Define the sink.
<2> Use it.
====

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
template <typename Callback>
constexpr Sink collect(Callback&& callback);

template <typename Container, typename Callback>
constexpr Sink collect(Callback&& callback);
}
----

Turns a callback into a sink by invoking it multiple times and collecting all the results in a container.

The first version requires that the callback returns `void`;
its sink callback forwards all arguments and increases a count.
The final count as a `std::size_t` is then returned by `finish()`.

The second version requires that the callback returns non-`void`.
Its sink callback creates a default constructed `Container`.
It then invokes the callback multiple times and adds the result to the container using `.push_back()`.
The final container is then returned.

NOTE: `collect()` is useful for the error callback to handle multiple errors.

==== Callback composition

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename First, typename Second>
    constexpr auto operator|(First first, Second second); // <1>

    template <typename Sink, typename Callback>
    constexpr auto operator>>(Sink sink, Callback callback); // <2>

}
----
<1> The result of `first | second`, where `first` and `second` are both callbacks, is another callback that first invokes `first` and then passes the result to `second`.
    The result cannot be used as sink.
<2> The  result of `sink >> callback`, is both a sink and a callback.
    As a sink, it behaves just like `sink`.
    As a callback, it takes the result of the `sink` as well as any other arguments and forwards them to `callback`.

.Example
[%collapsible]
====
Build a string, then get its length.

[source,cpp]
----
constexpr auto make_string = lexy::callback<std::string>([](const char* str) { return str; });
constexpr auto string_length = lexy::callback<std::size_t>(&std::string::size);

constexpr auto inefficient_strlen = make_string | string_length; // <1>

assert(inefficient_strlen("1234") == 4); // <2>
----
<1> Compose the two callbacks.
<2> Use it.
====

NOTE: The callback `operator>>` is used for productions whose rule contain both a list and produce other values.
The list will be constructed using the `sink` and then everything will be passed to `callback`.

==== The no-op callback

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
    constexpr auto noop = /* unspecified */;
}
----

`lexy::noop` is both a callback and a sink.
It ignores all arguments passed to it and its return type is `void`.

.Example
[%collapsible]
====
Parse the production, but do nothing on errors.

[source,cpp]
----
auto result = lexy::parse<my_production>(my_input, lexy::noop); // <1>
if (!result)
    throw my_parse_error(); // <2>
auto value = result.value(); // <3>
----
<1> Parse `my_production`. If an error occurs, just return a `result<T, void>` in the error state.
<2> `lexy::noop` does not make errors disappear, they still need to be handled.
<3> Do something with the parsed value.
====

==== Constructing objects

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename T>
    constexpr auto forward = /* unspecified */;

    template <typename T>
    constexpr auto construct = /* unspecified */;

    template <typename T, typename PtrT = T*>
    constexpr auto new_ = /* unspecified */;
}
----

The callback `lexy::forward<T>` can accept either a `const T&` or a `T&&` and forwards it.
It does not have a sink.

The callback `lexy::construct<T>` constructs a `T` by forwarding all arguments to a suitable constructor.
If the type does not have a constructor, it forwards all arguments using brace initialization.
It does not have a sink.

The callback `lexy::new_<T, PtrT>` works just like `lexy::construct<T>`, but it constructs the object on the heap by calling `new`.
The resulting pointer is then converted to the specified `PtrT`.
It does not have a sink.

.Example
[%collapsible]
====
A callback that creates a `std::unique_ptr<std::string>`.

[source,cpp]
----
constexpr auto make_unique_str = lexy::new_<std::string, std::unique_ptr<std::string>>; // <1>

constexpr auto make_unique_str2 = lexy::new_<std::string> | lexy::construct<std::unique_ptr<std::string>>; // <2>
----
<1> Specify a suitable `PtrT`.
<2> Equivalent version that uses composition and `lexy::construct` instead.
====

==== Constructing lists

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename T>
    constexpr auto as_list = /* unspecified */;

    template <typename T>
    constexpr auto as_collection = /* unspecified */;
}
----

`lexy::as_list<T>` is both a callback and a sink.
As a callback, it forwards all arguments to the `std::initializer_list` constructor of `T` and returns the result.
As a sink, it first default constructs a `T` and then repeatedly calls `push_back()` for single arguments and `emplace_back()` otherwise.

`lexy::as_collection<T>` is like `lexy::as_list<T>`, but instead of calling `push_back()` and `emplace_back()`, it calls `insert()` and `emplace()`.

.Example
[%collapsible]
====
Create a `std::vector<int>` and `std::set<int>`.

[source,cpp]
----
constexpr auto as_int_vector = lexy::as_list<std::vector<int>>;
constexpr auto as_int_set = lexy::as_collection<std::set<int>>;
----
====

==== Constructing strings

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename String, typename Encoding = /* see below */>
    constexpr auto as_string = /* unspecified */;
}
----

`lexy::as_string<String, Encoding>` is both a callback and a sink.
It constructs a `String` object in the given `Encoding`.
If no encoding is specified, it deduces one from the character type of the string.

As a callback, it constructs the string directly from the given argument.
Then it accepts:

* A reference to an existing `String` object, which is forwarded as the result.
* A `const CharT*` and a `std::size_t`, where `CharT` is a compatible character type. The two arguments are forwarded to a `String` constructor.
* A `lexy::lexeme<Reader> lex`, where `Reader::iterator` is a pointer.
  The character type of the reader must be compatible with the encoding.
  It constructs the string using `String(lex.data(), lex.size())` (potentially casting the pointer type if necessary).
* A `lexy::lexeme<Reader> lex`, where `Reader::iterator` is not a pointer.
  It constructs the string using `String(lex.begin(), lex.end())`.
  The range constructor has to take care of any necessary character conversion.
* A `lexy::code_point`. It is encoded into a local character array according to the specified `Encoding`.
  Then the string is constructed using a two-argument `(const CharT*, std::size_t)` constructor.

As a sink, it first default constructs the string.
Then it will repeatedly append the following arguments:

* A single `CharT`, which is convertible to the strings character type.
  It is appended by calling `.push_back()`.
* A reference to an existing `String` object, which is appended by calling `.append()`.
* A `const CharT*` and a `std::size_t`, where `CharT` is a compatible character type.
  The two arguments are forwarded to `.append()`.
* A `lexy::lexeme<Reader> lex`, where `Reader::iterator` is a pointer.
  The character type of the reader must be compatible with the encoding.
  It is appended using `.append(lex.data(), lex.size())` (potentially casting the pointer type if necessary).
* A `lexy::lexeme<Reader> lex`, where `Reader::iterator` is not a pointer.
  It constructs the string using `.append(lex.begin(), lex.end())`.
  The range append function has to take care of any necessary character conversion.
* A `lexy::code_point`. It is encoded into a local character array according to the specified `Encoding`.
  Then it is appended to the string using a two-argument `.append(const CharT*, std::size_t)` overload.

.Example
[%collapsible]
====
[source,cpp]
----
constexpr auto as_utf16_string = lexy::as_string<std::u16string>;                   // <1>
constexpr auto as_utf8_string  = lexy::as_string<std::string, lexy::utf8_encoding>; // <2>
----
<1> Constructs a `std::u16string`, deducing the encoding as UTF-16.
<2> Constructs a `std::string`, specifying the encoding as UTF-8.
====

==== Rule-specific callbacks

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename T>
    constexpr auto as_aggregate = /* unspecified */;

    template <typename T>
    constexpr auto as_integer = /* unspecified */;
}
----

The callback and sink `lexy::as_aggregate<T>` is only used together with the `lexy::dsl::member` rule and documented there.

The callback `lexy::as_integer<T>` constructs an integer type `T` and has two overloads:

[source,cpp]
----
template <typename Integer>
T operator()(const Integer& value) const; // <1>

template <typename Integer>
T operator()(int sign, const Integer& value) const; // <2>
----
<1> Returns `T(value)`.
<2> Returns `T(sign * value)`.

The second overload is meant to be used together with `lexy::dsl::sign` and related rules.

=== Error handling

Parsing errors are reported by constructing a `lexy::error` object and passing it to the error callback of `lexy::parse` and `lexy::validate` together with the `lexy::error_context`.
The error callback must either be a sink, in which case it can return an arbitrary type that represents a collection of all the errors,
or is a non-sink callback that returns `void`, in which case it will be passed to `lexy::collect()` to turn it into a sink.

The `error_type` of `lexy::validate_result` and `lexy::parse_result` will be the return type of the sink.
For a `void` returning non-sink callback it will be `std::size_t`, which is the result of `lexy::collect()`.

.Example
[%collapsible]
=====

.A `void`-returning error callback that is not a sink.
[source, cpp]
----
class ErrorCallbackVoid
{
public:
    using return_type = void;

    template <typename Production, typename Input, typename Tag>
    void operator()(const lexy::error_context<Production, Input>& context,
                           const lexy::error<lexy::input_reader<Input>, Tag>& error) const;
};
----

.A non-`void`-returning error callback that is a sink.
[source, cpp]
----
class ErrorCallbackSink
{
public:
    class Sink
    {
    public:
        using return_type = /* ... */;

        template <typename Production, typename Input, typename Tag>
        void operator()(const lexy::error_context<Production, Input>& context,
                               const lexy::error<lexy::input_reader<Input>, Tag>& error) const;

        return_type finish() &&;
    };

    Sink sink();
};
----

Of course, overloading can be used to differentiate between various error types and contexts.

=====

==== Error types

.`lexy/error.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename Reader, typename Tag>
    class error;

    struct expected_literal {};
    template <typename Reader>
    class error<Reader, expected_literal>;

    struct expected_keyword {};
    template <typename Reader>
    class error<Reader, expected_keyword>;

    struct expected_char_class {};
    template <typename Reader>
    class error<Reader, expected_char_class>;

    template <typename Input, typename Tag>
    using error_for = error<input_reader<Input>, Tag>;

    template <typename Reader, typename Tag, typename ... Args>
    constexpr auto make_error(Args&&... args);
}
----

All errors are represented by instantiations of `lexy::error<Reader, Tag>`.
The `Tag` is an empty type that specifies the kind of error.
There are specializations for two tags to store additional information.

The function `lexy::make_error` constructs an error object given the reader and tag by forwarding all the arguments.

===== Generic error

[source,cpp]
----
template <typename Reader, typename Tag>
class error
{
    using iterator = typename Reader::iterator;

public:
    constexpr explicit error(iterator pos) noexcept;
    constexpr explicit error(iterator begin, iterator end) noexcept;

    constexpr iterator position() const noexcept;

    constexpr iterator begin() const noexcept;
    constexpr iterator end() const noexcept;

    constexpr const char* message() const noexcept;
};
----

The primary class template `lexy::error<Reader, Tag>` represents a generic error without additional metadata.
It can either be constructed giving it a single position, then `position() == begin() == end()`;
or a range of the input, then `position() == begin() <= end()`.

The `message()` is determined using the `Tag`.
By default, it returns the type name of `Tag` after removing the top-level namespace name.
This can be overridden by defining either `Tag::name()` or `Tag::name`.

===== Expected literal error

[source,cpp]
----
struct expected_literal
{};

template <typename Reader>
class error<Reader, expected_literal>
{
    using iterator    = typename Reader::iterator;

public:
    constexpr explicit error(iterator position,
                             const typename Reader::char_type* string, std::size_t index) noexcept;

    constexpr iterator position() const noexcept;

    constexpr auto string() const noexcept -> const typename Reader::char_type*;
    constexpr auto character() const noexcept -> typename Reader::char_type;

    constexpr std::size_t index() const noexcept;
};
----

A specialization of `lexy::error` is provided if `Tag == lexy::expected_literal`.
It represents the error where a literal string was expected, but could not be matched.
It is mainly raised by the `lexy::dsl::lit` rule.

The error happens at a given `position()` and with a given `string()`.
The `index()` is the index into the string where matching failed; e.g. `0` if the input starts with a different character, `2` if the first two characters matched, etc.
The `character()` is the string character at that index.

===== Expected keyword error

[source,cpp]
----
struct expected_keyword
{};

template <typename Reader>
class error<Reader, expected_keyword>
{
    using iterator = typename Reader::iterator;

public:
    constexpr explicit error(iterator begin, iterator end,
                             const typename Reader::char_type* str);

    constexpr iterator position() const noexcept;
    constexpr iterator begin() const noexcept;
    constexpr iterator end() const noexcept;

    constexpr auto string() const noexcept -> const typename Reader::char_type*;
};
----

A specialization of `lexy::error` is provided if `Tag == lexy::expected_keyword`.
It represents the error where a keyword was expected, but could not be matched.
It is raised by the `lexy::dsl::keyword` rule.

The error happens at a given `position()` and with a given `string()`, which is the text of the keyword.
`begin()` and `end()` span the entire range of the identifier, which should have been `string()` but wasn't.

===== Character class error

[source,cpp]
----
struct expected_char_class
{};

template <typename Reader>
class error<Reader, expected_char_class>
{
    using iterator = typename Reader::iterator;

public:
    constexpr explicit error(iterator position, const char* name) noexcept;

    constexpr iterator position() const noexcept;

    constexpr const char* name() const noexcept;
};
----

A specialization of `lexy::error` is provided if `Tag == lexy::expected_char_class`.
It represents the error where any character from a given set of characters was expected, but could not be matched.
It is raised by the `lexy::dsl::ascii::*` rules or `lexy::dsl::newline`, among others.

The error happens at the given `position()` and a symbolic name of the character class is returned by `name()`.
By convention, the name format used is `<group>.<name>` or `<name>`, where both `<group>` and `<name>` consist of characters.
Examples include `newline`, `ASCII.alnum` and `digit.decimal`.

==== Error context

.`lexy/error.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename Production, typename Input>
    class error_context
    {
        using iterator = typename input_reader<Input>::iterator;

    public:
        constexpr explicit error_context(const Input& input, iterator pos) noexcept;

        constexpr const Input& input() const noexcept;

        static consteval const char* production();

        constexpr iterator position() const noexcept;
    };
}
----

The class `lexy::error_context<Production, Input>` contain information about the context where the error occurred.

The entire input containing the error is returned by `input()`.

The `Production` whose rule has raised the error is specified as template parameter and its name returned by `production()`.
Like `lexy::error<Reader, Tag>::message()`, it returns the name of the type without the top level namespace name.
This can be overridden by defining `Production::name()` or `Production::name`.

The `position()` of the error context is the input position where the production started parsing.

=== Parse Tree

.`lexy/parse_tree.hpp`
[source,cpp]
----
namespace lexy
{
    enum class traverse_event
    {
        enter,
        exit,
        leaf,
    };

    template <typename Reader, typename TokenKind = void,
              typename MemoryResource = /* default */>
    class parse_tree
    {
    public:
        class builder;

        constexpr parse_tree();
        constexpr explicit parse_tree(MemoryResource* resource);

        bool empty() const noexcept;
        void clear() noexcept;

        class node;
        class node_kind;

        node root() const noexcept; // requires: !empty()

        class traverse_range;

        traverse_range traverse(const node& n) const noexcept;
        traverse_range traverse() const noexcept;
    };

    template <typename Input, typename TokenKind = void,
              typename MemoryResource = /* default */>
    using parse_tree_for = lexy::parse_tree<input_reader<Input>, TokenKind, MemoryResource>;

    template <typename Production, typename TokenKind, typename MemoryResource, typename Input,
              typename ErrorCallback>
    auto parse_as_tree(parse_tree<input_reader<Input>, TokenKind, MemoryResource>& tree,
                       const Input& input, ErrorCallback error_callback)
      -> lexy::validate_result<ErrorCallback>;
}
----

The class `lexy::parse_tree` represents a lossless untyped syntax tree.

The function `lexy::parse_as_tree()` parses a `Production` on the given `input` and constructs a lossless parse tree from the result.
All parse errors are passed to the error callback (see <<Error handling>>) and later returned.
If a non-recoverable parse error happens, the tree will be cleared, otherwise it contains the (partial) parse tree of the input.
It will discard any values produced by parsing the rules.

The resulting parse tree will contain a parent node for each production, and leaf node for every token.
If a token is empty and has an unknown token kind, it will not be added to the parse tree.
If a production inherits from `lexy::transparent_production`, no separate node will be created;
instead all child nodes will be added to its parent.
If a production inherits from `lexy::token_production`, tokens are merged when possible:
if there are two or more tokens with the same kind directly after each other, only a single node spanning all of them will be added,
as opposed to multiple nodes for each individual token.

Traversing the tree and concatenating the lexemes of all tokens will result in the original input.

==== Manual Tree Building

[source,cpp]
----
template <typename Reader, typename TokenKind, typename MemoryResource>
class parse_tree<Reader, TokenKind, MemoryResource>::builder
{
public:
    template <typename Production>
    explicit builder(parse_tree&& tree, Production production); // <1>
    template <typename Production>
    explicit builder(Production production); // <2>

    struct production_state;

    template <typename Production>
    production_state start_production(Production production); // <3>

    void token(token_kind<TokenKind> kind,
               typename Reader::iterator begin, typename Reader::iterator end); // <4>

    void finish_production(production_state&& s); // <5>
    void backtrack_production(production_state&& s); // <6>

    parse_tree finish() &&; // <7>
};
----
<1> Create a builder that will re-use the memory of the existing `tree`.
    Its root node will be associated with the given `Production`.
<2> Same as above, but does not re-use memory.
<3> Adds a production child node as last child of the current node and activates it.
    Returns a handle that remembers the previous current node.
<4> Adds a token node to the current node.
<5> Finishes with a child production and activates its parent.
<6> Cancels the currently activated node, by deallocating it and all children.
    Activates its parent node again.
<7> Returns the finished tree.

==== Tree Node

[source,cpp]
----
template <typename Reader, typename TokenKind, typename MemoryResource>
class parse_tree<Reader, TokenKind, MemoryResource>::node_kind
{
public:
    bool is_token() const noexcept;
    bool is_production() const noexcept;

    bool is_root() const noexcept;
    bool is_token_production() const noexcept;

    const char* name() const noexcept;

    friend bool operator==(node_kind lhs, node_kind rhs);
    friend bool operator!=(node_kind lhs, node_kind rhs);

    friend bool operator==(node_kind nk, token_kind<TokenKind> tk);
    friend bool operator==(token_kind<TokenKind> tk, node_kind nk);
    friend bool operator!=(node_kind nk, token_kind<TokenKind> tk);
    friend bool operator!=(token_kind<TokenKind> tk, node_kind nk);

    template <typename Production>
    friend bool operator==(node_kind nk, Production);
    template <typename Production>
    friend bool operator==(Production p, node_kind nk);
    template <typename Production>
    friend bool operator!=(node_kind nk, Production p);
    template <typename Production>
    friend bool operator!=(Production p, node_kind nk);
};
----

The class `node_kind` stores information over the kind of node.
Nodes are either associated with a `Production` or a token rule.
The root node is always a `Production` node.

[source,cpp]
----
template <typename Reader, typename TokenKind, typename MemoryResource>
class parse_tree<Reader, TokenKind, MemoryResource>::node
{
public:
    void* address() const noexcept;

    node_kind kind() const noexcept;

    node parent() const noexcept;

    /* sized range */ children() const noexcept;

    /* range */ siblings() const noexcept;

    bool is_last_child() const noexcept;

    lexy::lexeme<Reader> lexeme() const noexcept;
    lexy::token<Reader, TokenKind> token() const noexcept;

    friend bool operator==(node lhs, node rhs) noexcept;
    friend bool operator!=(node lhs, node rhs) noexcept;
};
----

The class `node` is a reference to a node in the tree.
Two nodes are equal if and only if they point to the same node in the same tree.

===== Parent Access

[source,cpp]
----
node parent() const noexcept;
----

Returns a reference to a parent node.
For the root node, returns a reference to itself.

This operation is `O(number of siblings)`.

===== Child Access

[source,cpp]
----
class children_range
{
public:
    class iterator; // value_type = node
    class sentinel;

    iterator begin() const noexcept;
    sentinel end() const noexcept;

    bool empty() const noexcept;
    std::size_t size() const noexcept;
};

children_range children() const noexcept;
----

Returns a range object that iterates over all children of the node.
For a token node, this is always the empty range.

===== Sibling Access

[source,cpp]
----
class sibling_range
{
public:
    class iterator; // value_type = node

    iterator begin() const noexcept;
    iterator end() const noexcept;

    bool empty() const noexcept;
};

sibling_range siblings() const noexcept;
----

Returns a range object that iterates over all siblings of a node.
It begins with the sibling that is immediately following the node,
and continues until it reached the last child of the parent.
Then iteration wraps around to the first child of the parent until it ends at the original node.
The original node is not included in the sibling range.

===== Token Access

[source,cpp]
----
lexy::lexeme<Reader> lexeme() const noexcept; // <1>
lexy::token<Reader, TokenKind> token() const noexcept; // <2>
----
<1> Returns the spelling of a token node. For a production node, returns the empty lexeme.
<2> Returns the spelling and token kind of a token node; must not be called on a production node.

==== Tree Traversal

[source,cpp]
----
enum class traverse_event
{
    enter,
    exit,
    leaf,
};
----

[source,cpp]
----
class traverse_range
{
public:
    class iterator; // value_type = { traverse_event, node }

    iterator begin() const noexcept;
    iterator end() const noexcept;

    bool empty() const noexcept;
};

traverse_range traverse(const node& n) const noexcept; // <1>
traverse_range traverse() const noexcept; // <2>
----
<1> Returns a range that traverses descendants of the given node.
<2> Returns a range that traverses the root node, or an empty range if the tree is empty.

The `traverse_range` iterates over a node and all its children and their children and so on.
Its value type is a (unspecified) pair whose first member is a `lexy::traverse_event` and whose second member is a `node` reference.

For a token node, the range contains only the original node with event `leaf`.

For a production node, the range begins with the original node and event `enter`.
It then does an in-order traversal of all descendants, beginning with the children of a node.
When it reaches a token node, produces it with event `leaf`.
When it reaches a production node, produces it with event `enter`, then all its descendants recursively, and then with event `exit`.
After all descendants of the original node have been produced, finishes with the original node again and event `exit`.

.Example
[%collapsible]
=====

Prints a tree.

[source,cpp]
----
auto depth = 0;
for (auto [event, node] : tree.traverse())
{
    switch (event)
    {
    case lexy::traverse_event::enter:
        ++depth;
        indent(depth);
        print_node(node);
        break;
    case lexy::traverse_event::exit:
        --depth;
        break;

    case lexy::traverse_event::leaf:
        indent(depth);
        print_node(node);
        break;
    }
}
----
=====

NOTE: Traversing a node just does pointer chasing.
There is no allocation or recursion involved.

