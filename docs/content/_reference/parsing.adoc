== Matching, parsing and validating

.The `Production` concept
[source,cpp]
----
struct Production
{
    static constexpr auto rule = …;
    static constexpr auto whitespace = …; // optional

    static constexpr auto value = …; // optional
};
----

A `Production` is type containing a rule and optional callbacks that produce the value.
A grammar contains an entry production where parsing begins and all productions referenced by it.

TIP: It is recommended to put all productions of a grammar into a separate namespace.

By passing the entry production of the grammar to `lexy::match()`, `lexy::parse()`, or `lexy::validate()`, the production is parsed.

[discrete]
=== Matching

.`lexy/match.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename Production, typename Input>
    constexpr bool match(const Input& input);
}
----

The function `lexy::match()` matches the `Production` on the given `input`.
If the production accepts the input, returns `true`, otherwise, returns `false`.
It will discard any values produced and does not give detailed information about why the production did not accept the input.

NOTE: A production does not necessarily need to consume the entire input for it to match.
Add `lexy::dsl::eof` to the end if the production should consume the entire input.

[discrete]
=== Validating

.`lexy/validate.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename Production, typename Input, typename Callback>
    constexpr auto validate(const Input& input, Callback callback)
        -> result</* see below */>;
}
----

The function `lexy::validate()` validates that the `Production` matches on the given `input`.
The return value is an `lexy::result<void, E>`, where `E` is the return type of `callback`.
If the production accepts the input, returns an empty optional, otherwise, invokes the callback with the error information (see <<Error handling>>) and returns its result.
It will discard any values produced.

NOTE: A production does not necessarily need to consume the entire input for it to match.
Add `lexy::dsl::eof` to the end if the production should consume the entire input.

[discrete]
=== Parsing

.`lexy/parse.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename Production, typename Input, typename Callback>
    constexpr auto parse(const Input& input, Callback callback)
        -> result</* see below */>;

    template <typename Production, typename Input, typename State, typename Callback>
    constexpr auto parse(const Input& input, State&& state, Callback callback)
        -> result</* see below */>;
}
----

The function `lexy::parse()` parses the `Production` on the given `input`.
The return value is a `lexy::result<T, E>`, where `T` is the return type of the `Production::value` or `Production::list` callback,
and `E` is the return type of the `callback`.
If the production accepts the input, invokes `Production::value` (see below) with the produced values and returns their result.
Otherwise, invokes `callback` with the error information (see <<Error handling>>) and returns its result.

The return value on success is determined using `Production::value` depending on three cases:

* `Production::rule` does not contain a list. Then all arguments will be forwarded to `Production::value` as a callback whose result is returned.
  The `Production::value` callback must be present.
* `Production::rule` contains a list and no other rule produces a value. Then `Production::value` will be used as sink for the list values.
  If `Production::value` is also a callback that accepts the result of the sink as argument,
  it will be invoked with the sink result and the processed result returned.
  Otherwise, the result of the sink is the final result.
* `Production::rule` contains a list and other rules produce values as well.
  Then `Production::value` will be used as sink for the list values.
  The sink result will be added to the other values in order and everything forwarded to `Production::value` as a callback.
  The callback result is then returned.

NOTE: The callback `operator>>` is useful for case 3 to create a combined callback and sink with the desired behavior.

The second overload of `lexy::parse()` allows passing an arbitrary state argument.
This will be made available to the `lexy::dsl::parse_state` and `lexy::dsl::parse_state_member` rules which can forward it to the `Production::value` callback.

=== Result

.`lexy/result.hpp`
[source,cpp]
----
namespace lexy
{
    struct result_empty_t {};
    constexpr auto result_empty = result_empty_t{};

    struct result_value_t {};
    constexpr auto result_value = result_value_t{};

    struct result_error_t {};
    constexpr auto result_error = result_error_t{};

    template <typename T, typename E>
    class result
    {
    public:
        using value_type = /* see below */;
        using error_type = /* see below */;

        constexpr result(result_empty_t);

        template <typename... Args>
        constexpr result(result_value_t, Args&&... args);
        template <typename... Args>
        constexpr result(result_error_t, Args&&... args);

        template <typename U>
        constexpr explicit result(const result<U, E>& other);
        template <typename U>
        constexpr explicit result(result<U, E>&& other);

        template <typename Arg>
        constexpr explicit result(Arg&& arg);

        constexpr explicit operator bool() const noexcept;
        constexpr bool has_value() const noexcept;
        constexpr bool has_error() const noexcept;

        static constexpr bool has_void_value() noexcept;
        static constexpr bool has_void_error() noexcept;

        constexpr value_type& value() & noexcept;
        constexpr const value_type& value() const& noexcept;
        constexpr value_type&& value() && noexcept;
        constexpr const value_type&& value() const&& noexcept;

        constexpr error_type& error() & noexcept;
        constexpr const error_type& error() const& noexcept;
        constexpr error_type&& error() && noexcept;
        constexpr const error_type&& error() const&& noexcept;
    };
}
----

The class `lexy::result<T, E>` stores either a value `T` or an error `E` (or nothing) and is used to return the result of parsing.
`T` and `E` can be `void`; in that case it is internally translated to the tag types `result_value_t` or `result_error_t`, respectively, which is reflected in the `value_type` and `error_type` typedefs as well.

TIP: `lexy::result<T, void>` is like `std::optional<T>` and `lexy::result<void, void>` is like `bool`.

Once a result is created containing a value or error, it can never change that state.

NOTE: `lexy::result` was created for use by the library only.
While it can be used as a general purpose result monad (which we leverage for `lexy::read_file()`), it is better to us a designated library for it.

NOTE: Every `lexy::result` object returned by the library is never empty.
The empty state is just used internally and not exposed to the user (unless of course, the user explicitly creates an empty result).

[discrete]
===== Creation

[source,cpp]
----
constexpr result(result_empty_t); // <1>

template <typename... Args>
constexpr result(result_value_t, Args&&... args); // <2>
template <typename... Args>
constexpr result(result_error_t, Args&&... args); // <3>
----
<1> Creates a result that is empty.
<2> Creates a result containing the value constructed by forwarding the arguments.
<3> Creates a result containing the error constructed by forwarding the arguments.

[discrete]
===== Conversion

[source,cpp]
----
template <typename U>
constexpr explicit result(const result<U, E>& other); // <1>
template <typename U>
constexpr explicit result(result<U, E>&& other); // <2>

template <typename Arg>
constexpr explicit result(Arg&& arg); // <3>
----
<1> Converts an errored `result<U, E>` to a `result<T, E>` by copying the error.
<2> Converts an errored `result<U, E>` to a `result<T, E>` by moving the error.
<3> Only available for `result<T, void>` or `result<void, E>`. Constructs the value/error by forwarding the argument.

[discrete]
===== State

[source,cpp]
----
constexpr explicit operator bool() const noexcept; // <1>
constexpr bool is_empty() const noexcept;  // <2>
constexpr bool has_value() const noexcept; // <3>
constexpr bool has_error() const noexcept; // <4>

static constexpr bool has_void_value() noexcept; // <5>
static constexpr bool has_void_error() noexcept; // <6>
----
<1> Returns `true` if it contains a value, `false` otherwise.
<2> Returns `true` if it is empty (contains neither value nor error), `false` otherwise.
<3> Returns `true` if it contains a value, `false` otherwise.
<4> Returns `true` if it contains an error, `false` otherwise.
<5> Returns `true` if `T == void`, `false` otherwise.
<6> Returns `true` if `E == void`, `false` otherwise.

[discrete]
===== Access

[source,cpp]
----
constexpr value_type& value() & noexcept;
constexpr const value_type& value() const& noexcept;
constexpr value_type&& value() && noexcept;
constexpr const value_type&& value() const&& noexcept;

constexpr error_type& error() & noexcept;
constexpr const error_type& error() const& noexcept;
constexpr error_type&& error() && noexcept;
constexpr const error_type&& error() const&& noexcept;
----

Returns the stored value or error, respectively.

=== Callbacks

.The `Callback` concept
[source,cpp]
----
struct Callback
{
    using return_type = …;

    return_type operator()(Args&&... args) const;
};

struct Sink
{
    class _sink // exposition only
    {
    public:
        using return_type = …;

        void operator()(Args&&... args);

        return_type&& finish() &&;
    };

    _sink sink() const;
};
----

A `Callback` is a function object whose return type is specified by a member typedef.
A `Sink` is a type with a `sink()` member function that returns a callback.
The callback can be invoked multiple times and the final value is return by calling `.finish()`.

Callbacks are used by `lexy` to compute the parse result and handle error values.
They can either be written manually implementing to the above concepts or composed from the pre-defined concepts.

==== Callback adapters

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename ReturnType = void, typename... Fns>
    constexpr Callback callback(Fns&&... fns);
}
----

Creates a callback with the given `ReturnType` from multiple functions.
When calling the resulting callback, it will use overload resolution to determine the correct function to call.
It supports function pointers, lambdas, and member function or data pointers.

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename T, typename... Fns>
    constexpr Sink sink(Fns&&... fns);
}
----

Creates a sink constructing the given `T` using the given functions.
The sink will value-construct the `T` and then call one of the functions selected by overload resolution, passing it a reference to the resulting object as first argument.
It supports function pointers, lambdas, and member function or data pointers.

.Example
[%collapsible]
====
Creating a sink that will add all values.

[source,cpp]
----
constexpr auto adder = lexy::sink<int>([](int& cur, int arg) { cur += arg; }); // <1>

auto s = adder.sink(); // <2>
s(1);
s(2);
s(3);
auto result = std::move(s).finish();
assert(result == 1 + 2 + 3);
----
<1> Define the sink.
<2> Use it.
====

==== Callback composition

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename First, typename Second>
    constexpr auto operator|(First first, Second second); // <1>

    template <typename Sink, typename Callback>
    constexpr auto operator>>(Sink sink, Callback callback); // <2>

}
----
<1> The result of `first | second`, where `first` and `second` are both callbacks, is another callback that first invokes `first` and then passes the result to `second`.
    The result cannot be used as sink.
<2> The  result of `sink | callback`, is a sink and a callback.
    As a sink, it behaves just like `sink`.
    As a callback, it takes the result of the `sink` as well as any other arguments and forwards them to `callback`.

.Example
[%collapsible]
====
Build a string, then get its length.

[source,cpp]
----
constexpr auto make_string = lexy::callback<std::string>([](const char* str) { return str; });
constexpr auto string_length = lexy::callback<std::size_t>(&std::string::size);

constexpr auto inefficient_strlen = make_string | string_length; // <1>

assert(inefficient_strlen("1234") == 4); // <2>
----
<1> Compose the two callbacks.
<2> Use it.
====

NOTE: The callback `operator>>` is used for productions whose rule contain both a list and produce other values.
The list will be constructed using the `sink` and then everything will be passed to `callback`.

==== The no-op callback

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
    constexpr auto noop = /* unspecified */;
}
----

`lexy::noop` is both a callback and a sink.
It ignores all arguments passed to it and its return type is `void`.

.Example
[%collapsible]
====
Parse the production, but do nothing on errors.

[source,cpp]
----
auto result = lexy::parse<my_production>(my_input, lexy::noop); // <1>
if (!result)
    throw my_parse_error(); // <2>
auto value = result.value(); // <3>
----
<1> Parse `my_production`. If an error occurs, just return a `result<T, void>` in the error state.
<2> `lexy::noop` does not make errors disappear, they still need to be handled.
<3> Do something with the parsed value.
====

==== Constructing objects

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename T>
    constexpr auto forward = /* unspecified */;

    template <typename T>
    constexpr auto construct = /* unspecified */;

    template <typename T, typename PtrT = T*>
    constexpr auto new_ = /* unspecified */;
}
----

The callback `lexy::forward<T>` can accept either a `const T&` or a `T&&` and forwards it.
It does not have a sink.

The callback `lexy::construct<T>` constructs a `T` by forwarding all arguments to a suitable constructor.
If the type does not have a constructor, it forwards all arguments using brace initialization.
It does not have a sink.

The callback `lexy::new_<T, PtrT>` works just like `lexy::construct<T>`, but it constructs the object on the heap by calling `new`.
The resulting pointer is then converted to the specified `PtrT`.
It does not have a sink.

.Example
[%collapsible]
====
A callback that creates a `std::unique_ptr<std::string>`.

[source,cpp]
----
constexpr auto make_unique_str = lexy::new_<std::string, std::unique_ptr<std::string>>; // <1>

constexpr auto make_unique_str2 = lexy::new_<std::string> | lexy::construct<std::unique_ptr<std::string>>; // <2>
----
<1> Specify a suitable `PtrT`.
<2> Equivalent version that uses composition and `lexy::construct` instead.
====

==== Constructing lists

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename T>
    constexpr auto as_list = /* unspecified */;

    template <typename T>
    constexpr auto as_collection = /* unspecified */;
}
----

`lexy::as_list<T>` is both a callback and a sink.
As a callback, it forwards all arguments to the `std::initializer_list` constructor of `T` and returns the result.
As a sink, it first default constructs a `T` and then repeatedly calls `push_back()` for single arguments and `emplace_back()` otherwise.

`lexy::as_collection<T>` is like `lexy::as_list<T>`, but instead of calling `push_back()` and `emplace_back()`, it calls `insert()` and `emplace()`.

.Example
[%collapsible]
====
Create a `std::vector<int>` and `std::set<int>`.

[source,cpp]
----
constexpr auto as_int_vector = lexy::as_list<std::vector<int>>;
constexpr auto as_int_set = lexy::as_collection<std::set<int>>;
----
====

==== Constructing strings

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename String, typename Encoding = /* see below */>
    constexpr auto as_string = /* unspecified */;
}
----

`lexy::as_string<String, Encoding>` is both a callback and a sink.
It constructs a `String` object in the given `Encoding`.
If no encoding is specified, it deduces one from the character type of the string.

As a callback, it constructs the string directly from the given argument.
Then it accepts:

* A reference to an existing `String` object, which is forwarded as the result.
* A `const CharT*` and a `std::size_t`, where `CharT` is a compatible character type. The two arguments are forwarded to a `String` constructor.
* A `lexy::lexeme<Reader> lex`, where `Reader::iterator` is a pointer.
  The character type of the reader must be compatible with the encoding.
  It constructs the string using `String(lex.data(), lex.size())` (potentially casting the pointer type if necessary).
* A `lexy::lexeme<Reader> lex`, where `Reader::iterator` is not a pointer.
  It constructs the string using `String(lex.begin(), lex.end())`.
  The range constructor has to take care of any necessary character conversion.
* A `lexy::code_point`. It is encoded into a local character array according to the specified `Encoding`.
  Then the string is constructed using a two-argument `(const CharT*, std::size_t)` constructor.

As a sink, it first default constructs the string.
Then it will repeatedly append the following arguments:

* A single `CharT`, which is convertible to the strings character type.
  It is appended by calling `.push_back()`.
* A reference to an existing `String` object, which is appended by calling `.append()`.
* A `const CharT*` and a `std::size_t`, where `CharT` is a compatible character type.
  The two arguments are forwarded to `.append()`.
* A `lexy::lexeme<Reader> lex`, where `Reader::iterator` is a pointer.
  The character type of the reader must be compatible with the encoding.
  It is appended using `.append(lex.data(), lex.size())` (potentially casting the pointer type if necessary).
* A `lexy::lexeme<Reader> lex`, where `Reader::iterator` is not a pointer.
  It constructs the string using `.append(lex.begin(), lex.end())`.
  The range append function has to take care of any necessary character conversion.
* A `lexy::code_point`. It is encoded into a local character array according to the specified `Encoding`.
  Then it is appended to the string using a two-argument `.append(const CharT*, std::size_t)` overload.

.Example
[%collapsible]
====
[source,cpp]
----
constexpr auto as_utf16_string = lexy::as_string<std::u16string>;                   // <1>
constexpr auto as_utf8_string  = lexy::as_string<std::string, lexy::utf8_encoding>; // <2>
----
<1> Constructs a `std::u16string`, deducing the encoding as UTF-16.
<2> Constructs a `std::string`, specifying the encoding as UTF-8.
====

==== Rule-specific callbacks

.`lexy/callback.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename T>
    constexpr auto as_aggregate = /* unspecified */;

    template <typename T>
    constexpr auto as_integer = /* unspecified */;
}
----

The callback and sink `lexy::as_aggregate<T>` is only used together with the `lexy::dsl::member` rule and documented there.

The callback `lexy::as_integer<T>` constructs an integer type `T` and has two overloads:

[source,cpp]
----
template <typename Integer>
T operator()(const Integer& value) const; // <1>

template <typename Integer>
T operator()(int sign, const Integer& value) const; // <2>
----
<1> Returns `T(value)`.
<2> Returns `T(sign * value)`.

The second overload is meant to be used together with `lexy::dsl::sign` and related rules.

=== Error handling

Parsing errors are reported by constructing a `lexy::error` object and passing it to the error callback of `lexy::parse` and `lexy::validate` together with the `lexy::error_context`.

As such, an error callback looks like this:

[source, cpp]
----
class ErrorCallback
{
public:
    using return_type = /* … */;

    template <typename Production, typename Input, typename Tag>
    return_type operator()(const lexy::error_context<Production, Input>& context,
                           const lexy::error<lexy::input_reader<Input>, Tag>& error) const;
};
----

Of course, overloading can be used to differentiate between various error types and contexts.

==== Error types

.`lexy/error.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename Reader, typename Tag>
    class error;

    struct expected_literal {};
    template <typename Reader>
    class error<Reader, expected_literal>;

    struct expected_char_class {};
    template <typename Reader>
    class error<Reader, expected_char_class>;

    template <typename Input, typename Tag>
    using error_for = error<input_reader<Input>, Tag>;

    template <typename Reader, typename Tag, typename ... Args>
    constexpr auto make_error(Args&&... args);
}
----

All errors are represented by instantiations of `lexy::error<Reader, Tag>`.
The `Tag` is an empty type that specifies the kind of error.
There are specializations for two tags to store additional information.

The function `lexy::make_error` constructs an error object given the reader and tag by forwarding all the arguments.

===== Generic error

[source,cpp]
----
template <typename Reader, typename Tag>
class error
{
    using iterator = typename Reader::iterator;

public:
    constexpr explicit error(iterator pos) noexcept;
    constexpr explicit error(iterator begin, iterator end) noexcept;

    constexpr iterator position() const noexcept;

    constexpr iterator begin() const noexcept;
    constexpr iterator end() const noexcept;

    constexpr const char* message() const noexcept;
};
----

The primary class template `lexy::error<Reader, Tag>` represents a generic error without additional metadata.
It can either be constructed giving it a single position, then `position() == begin() == end()`;
or a range of the input, then `position() == begin() <= end()`.

The `message()` is determined using the `Tag`.
By default, it returns the type name of `Tag` after removing the top-level namespace name.
This can be overridden by defining either `Tag::name()` or `Tag::name`.

===== Expected literal error

[source,cpp]
----
struct expected_literal
{};

template <typename Reader>
class error<Reader, expected_literal>
{
    using iterator    = typename Reader::iterator;

public:
    constexpr explicit error(iterator position,
                             string_view string, std::size_t index) noexcept;

    constexpr iterator position() const noexcept;

    constexpr auto string() const noexcept -> const typename Reader::char_type*;
    constexpr auto character() const noexcept -> typename Reader::char_type;

    constexpr std::size_t index() const noexcept;
};
----

A specialization of `lexy::error` is provided if `Tag == lexy::expected_literal`.
It represents the error where a literal string was expected, but could not be matched.
It is mainly raised by the `lexy::dsl::lit` rule.

The error happens at a given `position()` and with a given `string()`.
The `index()` is the index into the string where matching failed; e.g. `0` if the input starts with a different character, `2` if the first two characters matched, etc.
The `character()` is the string character at that index.

===== Character class error

[source,cpp]
----
struct expected_char_class
{};

template <typename Reader>
class error<Reader, expected_char_class>
{
    using iterator = typename Reader::iterator;

public:
    constexpr explicit error(iterator position, const char* name) noexcept;

    constexpr iterator position() const noexcept;

    constexpr const char* name() const noexcept;
};
----

A specialization of `lexy::error` is provided if `Tag == lexy::expected_char_class`.
It represents the error where any character from a given set of characters was expected, but could not be matched.
It is raised by the `lexy::dsl::ascii::*` rules or `lexy::dsl::newline`, among others.

The error happens at the given `position()` and a symbolic name of the character class is returned by `name()`.
By convention, the name format used is `<group>.<name>` or `<name>`, where both `<group>` and `<name>` consist of characters.
Examples include `newline`, `ASCII.alnum` and `digit.decimal`.

==== Error context

.`lexy/error.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename Production, typename Input>
    class error_context
    {
        using iterator = typename input_reader<Input>::iterator;

    public:
        constexpr explicit error_context(const Input& input, iterator pos) noexcept;

        constexpr const Input& input() const noexcept;

        static consteval const char* production();

        constexpr iterator position() const noexcept;
    };
}
----

The class `lexy::error_context<Production, Input>` contain information about the context where the error occurred.

The entire input containing the error is returned by `input()`.

The `Production` whose rule has raised the error is specified as template parameter and its name returned by `production()`.
Like `lexy::error<Reader, Tag>::message()`, it returns the name of the type without the top level namespace name.
This can be overridden by defining `Production::name()` or `Production::name`.

The `position()` of the error context is the input position where the production started parsing.

==== Error location

.`lexy/error_location.hpp`
[source,cpp]
----
namespace lexy
{
    template <typename Reader>
    struct error_location
    {
        std::size_t line, column;
        lexeme<Reader> context;
    };

    template <typename Input>
    using error_location_for = error_location<input_reader<Input>>;

    template <typename Input, typename TokenCP, typename TokenNL>
    constexpr auto make_error_location(const Input& input,
                                       typename input_reader<Input>::iterator pos,
                                       TokenCP code_point_token,
                                       TokenNL newline_token)
        -> error_location_for<Input>;
}
----

The header `lexy/error_location.hpp` provides a utility function `lexy::make_error_location()` to convert an error position,
which is always given via an iterator, into the traditional line/column format.

The function takes the position into the input, as well as two tokens.
It then determines the line and column by repeatedly parsing the two tokens until the error position is reached.
Every time the `code_point_token` matches, the column is increased by one.
Every time the `newline_token` matches, the column is reset to one and the line increased by one.
If neither token matches, column is increased by one and the next code unit skipped.
The final line and column number are returned, together with the `context` which is a lexeme containing the entire line where the error occurred.

For ASCII encoded texts, the `code_point_token` is `lexy::dsl::ascii::character` and the `newline_token` is `lexy::dsl::newline`.
For Unicode encoded texts, the `code_point_token` is `lexy::dsl::code_point` and the `newline_token` is `lexy::dsl::newline`.

=== Parse Tree

.`lexy/parse_tree.hpp`
[source,cpp]
----
namespace lexy
{
    enum class traverse_event
    {
        enter,
        exit,
        leaf,
    };

    template <typename Reader, typename TokenKind = void,
              typename MemoryResource = /* default */>
    class parse_tree
    {
    public:
        class builder;

        constexpr parse_tree();
        constexpr explicit parse_tree(MemoryResource* resource);

        bool empty() const noexcept;
        void clear() noexcept;

        class node;
        class node_kind;

        node root() const noexcept; // requires: !empty()

        class traverse_range;

        traverse_range traverse(const node& n) const noexcept;
        traverse_range traverse() const noexcept;
    };

    template <typename Input, typename TokenKind = void,
              typename MemoryResource = /* default */>
    using parse_tree_for = lexy::parse_tree<input_reader<Input>, TokenKind, MemoryResource>;

    template <typename Production, typename TokenKind, typename MemoryResource, typename Input,
              typename Callback>
    auto parse_as_tree(parse_tree<input_reader<Input>, TokenKind, MemoryResource>& tree,
                       const Input& input, Callback callback)
      -> result<void, typename Callback::return_type>;
}
----

The class `lexy::parse_tree` represents a lossless untyped syntax tree.

The function `lexy::parse_as_tree()` parses a `Production` on the given `input` and constructs a lossless parse tree from the result.
The return value is an `lexy::result<void, E>`, where `E` is the return type of `callback`.
If the production accepts the input, returns an empty optional and updates `tree` to the parse tree, otherwise, cleares the `tree` and invokes the callback with the error information (see <<Error handling>>) and returns its result.
It will discard any values produced by parsing the rules.

The resulting parse tree will contain a parent node for each production, and leaf node for every token.
If a token is empty, it will not be added to the parse tree.
If a production inherits from `lexy::transparent_production`, no separate node will be created;
instead all child nodes will be added to its parent.
Traversing the tree and concatenating the lexemes of all tokens will result in the original input.

==== Manual Tree Building

[source,cpp]
----
template <typename Reader, typename TokenKind, typename MemoryResource>
class parse_tree<Reader, TokenKind, MemoryResource>::builder
{
public:
    template <typename Production>
    explicit builder(parse_tree&& tree, Production production); // <1>
    template <typename Production>
    explicit builder(Production production); // <2>

    struct production_state;

    template <typename Production>
    production_state start_production(Production production); // <3>
    void finish_production(production_state&& s); // <4>

    void token(token_kind<TokenKind> kind,
               typename Reader::iterator begin, typename Reader::iterator end); // <5>

    parse_tree finish() &&; // <6>
};
----
<1> Create a builder that will re-use the memory of the existing `tree`.
    Its root node will be associated with the given `Production`.
<2> Same as above, but does not re-use memory.
<3> Adds a production child node as last child of the current node and activates it.
    Returns a handle that remembers the previous current node.
<4> Finishes with a child production and activates its parent.
<5> Adds a token node to the current node.
<6> Returns the finished tree.

==== Tree Node

[source,cpp]
----
template <typename Reader, typename TokenKind, typename MemoryResource>
class parse_tree<Reader, TokenKind, MemoryResource>::node_kind
{
public:
    bool is_root() const noexcept;

    bool is_token() const noexcept;
    bool is_production() const noexcept;

    auto name() const noexcept;

    friend bool operator==(node_kind lhs, node_kind rhs);
    friend bool operator!=(node_kind lhs, node_kind rhs);

    friend bool operator==(node_kind nk, token_kind<TokenKind> tk);
    friend bool operator==(token_kind<TokenKind> tk, node_kind nk);
    friend bool operator!=(node_kind nk, token_kind<TokenKind> tk);
    friend bool operator!=(token_kind<TokenKind> tk, node_kind nk);

    template <typename Production>
    friend bool operator==(node_kind nk, Production);
    template <typename Production>
    friend bool operator==(Production p, node_kind nk);
    template <typename Production>
    friend bool operator!=(node_kind nk, Production p);
    template <typename Production>
    friend bool operator!=(Production p, node_kind nk);
};
----

The class `node_kind` stores information over the kind of node.
Nodes are either associated with a `Production` or a token rule.
The root node is always a `Production` node.

[source,cpp]
----
template <typename Reader, typename TokenKind, typename MemoryResource>
class parse_tree<Reader, TokenKind, MemoryResource>::node
{
public:
    void* address() const noexcept;

    node_kind kind() const noexcept;

    node parent() const noexcept;

    /* sized range */ children() const noexcept;

    /* range */ siblings() const noexcept;

    bool is_last_child() const noexcept;

    lexy::lexeme<Reader> lexeme() const noexcept;
    lexy::token<Reader, TokenKind> token() const noexcept;

    friend bool operator==(node lhs, node rhs) noexcept;
    friend bool operator!=(node lhs, node rhs) noexcept;
};
----

The class `node` is a reference to a node in the tree.
Two nodes are equal if and only if they point to the same node in the same tree.

===== Parent Access

[source,cpp]
----
node parent() const noexcept;
----

Returns a reference to a parent node.
For the root node, returns a reference to itself.

This operation is `O(number of siblings)`.

===== Child Access

[source,cpp]
----
class children_range
{
public:
    class iterator; // value_type = node
    class sentinel;

    iterator begin() const noexcept;
    sentinel end() const noexcept;

    bool empty() const noexcept;
    std::size_t size() const noexcept;
};

children_range children() const noexcept;
----

Returns a range object that iterates over all children of the node.
For a token node, this is always the empty range.

===== Sibling Access

[source,cpp]
----
class sibling_range
{
public:
    class iterator; // value_type = node

    iterator begin() const noexcept;
    iterator end() const noexcept;

    bool empty() const noexcept;
};

sibling_range siblings() const noexcept;
----

Returns a range object that iterates over all siblings of a node.
It begins with the sibling that is immediately following the node,
and continues until it reached the last child of the parent.
Then iteration wraps around to the first child of the parent until it ends at the original node.
The original node is not included in the sibling range.

===== Token Access

[source,cpp]
----
lexy::lexeme<Reader> lexeme() const noexcept; // <1>
lexy::token<Reader, TokenKind> token() const noexcept; // <2>
----
<1> Returns the spelling of a token node. For a production node, returns the empty lexeme.
<2> Returns the spelling and token kind of a token node; must not be called on a production node.

==== Tree Traversal

[source,cpp]
----
enum class traverse_event
{
    enter,
    exit,
    leaf,
};
----

[source,cpp]
----
class traverse_range
{
public:
    class iterator; // value_type = { traverse_event, node }

    iterator begin() const noexcept;
    iterator end() const noexcept;

    bool empty() const noexcept;
};

traverse_range traverse(const node& n) const noexcept; // <1>
traverse_range traverse() const noexcept; // <2>
----
<1> Returns a range that traverses descendants of the given node.
<2> Returns a range that traverses the root node, or an empty range if the tree is empty.

The `traverse_range` iterates over a node and all its children and their children and so on.
Its value type is a (unspecified) pair whose first member is a `lexy::traverse_event` and whose second member is a `node` reference.

For a token node, the range contains only the original node with event `leaf`.

For a production node, the range begins with the original node and event `enter`.
It then does an in-order traversal of all descendants, beginning with the children of a node.
When it reaches a token node, produces it with event `leaf`.
When it reaches a production node, produces it with event `enter`, then all its descendants recursively, and then with event `exit`.
After all descendants of the original node have been produced, finishes with the original node again and event `exit`.

.Example
[%collapsible]
=====

Prints a tree.

[source,cpp]
----
auto depth = 0;
for (auto [event, node] : tree.traverse())
{
    switch (event)
    {
    case lexy::traverse_event::enter:
        ++depth;
        indent(depth);
        print_node(node);
        break;
    case lexy::traverse_event::exit:
        --depth;
        break;

    case lexy::traverse_event::leaf:
        indent(depth);
        print_node(node);
        break;
    }
}
----
=====

NOTE: Traversing a node just does pointer chasing.
There is no allocation or recursion involved.

